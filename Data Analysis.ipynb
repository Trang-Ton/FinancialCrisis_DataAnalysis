{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890cc3f4",
   "metadata": {},
   "source": [
    "#        Did financial crisis 2008-2009 impact on EU firms' capital structures?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792af67",
   "metadata": {},
   "source": [
    "### This document intends to provide source codes in order to replicate the analysis with different dataset\n",
    "Owner: Trang Ton\n",
    "\n",
    "Dataset used in this study is from Osiris Database. Due to different data sources, data cleaning steps might be different.\n",
    "\n",
    "The regression analysis is not comprehensive and might ignore other financial factors that could impact the firms' capital structures. However, I hope this would give you prior ideas for further research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from docx import Document\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from linearmodels.panel import PanelOLS # using for panel regression\n",
    "from linearmodels.panel import compare # creating combined table of results - panel analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = '# Data path'\n",
    "df = pd.read_csv(DATA_FILE, encoding = 'input file encoding')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279af671",
   "metadata": {},
   "source": [
    "# 1. Transforming into panel data\n",
    "\n",
    "The dataset is extracted from Osiris database. Afer exporting raw data from Osiris, transforming into panel setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e059e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change column names before transforming\n",
    "\n",
    "# Loop to drop 'm EUR' in variable names\n",
    "COL = list(df.columns)\n",
    "dic = dict()\n",
    "label = ' m EUR '\n",
    "for col in COL:\n",
    "    if label in col:\n",
    "        new_name = col.replace(label, '')\n",
    "        dic[col] = new_name\n",
    "df = df.rename(columns = dic)\n",
    "\n",
    "# Loop to drop ' % ' in variable names\n",
    "COL = list(df.columns)\n",
    "dic = dict()\n",
    "label = ' % '\n",
    "for col in COL:\n",
    "    if label in col:\n",
    "        new_name = col.replace(label, '')\n",
    "        dic[col] = new_name\n",
    "df = df.rename(columns = dic)\n",
    "\n",
    "\n",
    "# Drop columns with 'Last avail. yr' terms\n",
    "COL = list(df.columns)\n",
    "label_drop = 'Last avail. yr'\n",
    "for col in COL:\n",
    "    if label_drop in col:\n",
    "        df = df.drop(columns = col)\n",
    "        \n",
    "# Rename Number of employees columns\n",
    "COL = list(df.columns)\n",
    "dic = dict()\n",
    "label = '.1'\n",
    "for col in COL:\n",
    "    if label in col:\n",
    "        new_name = col.replace(label, '')\n",
    "        dic[col] = new_name\n",
    "df = df.rename(columns = dic)\n",
    "\n",
    "# Rename Number of employees columns\n",
    "COL = list(df.columns)\n",
    "dic = dict()\n",
    "label = 'Number of employees  '\n",
    "for col in COL:\n",
    "    if label in col:\n",
    "        new_name = col.replace(label, 'Number of employees')\n",
    "        dic[col] = new_name\n",
    "df = df.rename(columns = dic)\n",
    "\n",
    "#remove duplicate columns\n",
    "duplicated_columns = df.columns.duplicated()\n",
    "\n",
    "df = df.loc[:, ~duplicated_columns]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transforming the data set inro panel setting\n",
    "\n",
    "year_arr = list(range(2004, 2013))\n",
    "year_arr\n",
    "\n",
    "COL = list(df.columns)\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "df_array = []\n",
    "for year in year_arr:\n",
    "    \n",
    "    df_yearly = pd.DataFrame()\n",
    "    df_yearly['Company'] = df['Company name']\n",
    "    df_yearly['Year'] = year\n",
    "    df_yearly['Country'] = df['Country - (address of incorp.)']\n",
    "    df_yearly['GICS'] = df['GICS code']\n",
    "    df_yearly['GICS Description'] = df['GICS description']\n",
    "    \n",
    "    for col in COL:\n",
    "        if (f'{year}') in col:\n",
    "            var = col.replace(f'{year}', '')\n",
    "            df_yearly[var] = df[col]\n",
    "            \n",
    "    df_final = pd.concat([df_final, df_yearly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b5192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### drop duplicated column Total Assets\n",
    "\n",
    "df_final=df_final.drop(columns='Total Assets')\n",
    "\n",
    "### Sort dataframe by company names and years\n",
    "df_sort = df_final.sort_values(by=['Company', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7515ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export Panel dataset and save as csv file\n",
    "\n",
    "df_sort.to_csv('raw_EU27_panel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c20a3",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "\n",
    "### Applying cleaning functions, categorizing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5efca3",
   "metadata": {},
   "source": [
    "1. Cleaning functions: Replace missing value, modifying data types, classify industries, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197cf223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all used variables\n",
    "\n",
    "EU19_list = ['AUSTRIA','BELGIUM','CYPRUS','ESTONIA','FINLAND',\n",
    "             'FRANCE','GERMANY','GREECE','IRELAND','ITALY','LATVIA','LITHUANIA',\n",
    "             'LUXEMBOURG','MALTA','NETHERLANDS','PORTUGAL','SLOVAKIA','SLOVENIA','SPAIN']\n",
    "\n",
    "var_list = ['Total assets', 'Net sales','Total liabilities',\n",
    "            'Market Cap.', 'ROA', 'Net debt',\n",
    "           'Number of employees', 'Intangible assets']\n",
    "non_missing_col = ['Total assets', 'Net sales','Total liabilities', 'Market Cap.']\n",
    "positive_col = ['Total assets', 'Net sales','Total liabilities']\n",
    "non_zero_col = ['Total assets', 'Net sales','Total liabilities', 'Market Cap.']\n",
    "excluded_industries = ['Financials']\n",
    "\n",
    "dtype_dic = {'Total assets': 'int64',\n",
    "             'Net sales': 'int64',\n",
    "             'Total liabilities': 'int64',\n",
    "            'Market Cap.': 'int64'}\n",
    "\n",
    "rename_dic = {'Return on assets (ROA)': 'ROA',\n",
    "             'Number of employees ': 'Number of employees'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function_1 to clean missing values and change data types\n",
    "\n",
    "def dataframe_cleaning(df, non_missing_col, positive_col, non_zero_col, dtype_dic):\n",
    "    # missing value filter\n",
    "    df = df.dropna(subset = non_missing_col)\n",
    "    \n",
    "    # dropping duplicate values\n",
    "    df = df.drop_duplicates(subset = ['Company', 'Year'])\n",
    "    \n",
    "    # fix datatypes\n",
    "    df = df.astype(dtype_dic)\n",
    "    \n",
    "    # filter for insolvency\n",
    "    for col in positive_col:\n",
    "        df = df.loc[df[col] > 0]\n",
    "        \n",
    "    #filter for non zero values\n",
    "    for col in non_zero_col:\n",
    "        df = df.loc[df[col] != 0]\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function_2 to classify industry\n",
    "\n",
    "industry_dic = {'Energy': 10,\n",
    "               'Materials': 15,\n",
    "               'Industrials': 20,\n",
    "               'Consumer Discretionary': 25,\n",
    "               'Consumer Staples': 30,\n",
    "               'Health Care': 35,\n",
    "               'Financials': 40,\n",
    "               'Information Technology': 45,\n",
    "               'Communication Services': 50,\n",
    "               'Utilities': 55,\n",
    "               'Real Estate': 60}\n",
    "def get_key_from_value(dictionary, value):\n",
    "    for key in dictionary:\n",
    "        if dictionary[key] == value:\n",
    "            return key\n",
    "    # If the value is not found, return None or raise an exception\n",
    "    return None\n",
    "def industry_classifier (GICS):\n",
    "    industry = get_key_from_value(industry_dic,int(str(GICS)[:2]))\n",
    "    return industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function_3 to filter industries\n",
    "\n",
    "def sample_filter(df, industry_col, excluded_industries):\n",
    "    # filter for financial firms\n",
    "    df = df.loc[~df[industry_col].isin(excluded_industries)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b18708",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function_4: Winsorization \n",
    "\n",
    "def winsorization(df, variables, lower_thresh = 0.01, upper_thresh = 0.99, by = 'Year', suffix = '_w'):\n",
    "    dfs = []\n",
    "\n",
    "    categories = df[by].unique()\n",
    "\n",
    "    for cat in categories:\n",
    "        df_cat = df.loc[df[by] == cat]\n",
    "\n",
    "        for var in variables:\n",
    "            df_cat[f'{var}{suffix}'] = df_cat[var].clip(lower = df_cat[var].dropna().quantile(lower_thresh),\n",
    "                                                        upper = df_cat[var].dropna().quantile(upper_thresh))\n",
    "        dfs.append(df_cat)\n",
    "\n",
    "    df_output = pd.concat(dfs)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f81f74",
   "metadata": {},
   "source": [
    " 2. Applying functions: import panel data, applying cleaning processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import new raw panel\n",
    "DATA_FILE = '/Users/tonnunhatrang/Desktop/Data analysis/Python/Essay_AMA3/EU27_raw_detailed/raw_EU27_panel.csv'\n",
    "df = pd.read_csv(DATA_FILE, encoding = 'utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying cleaning processes\n",
    "df = df.rename(columns = rename_dic)\n",
    "\n",
    "df_clean = dataframe_cleaning(df, non_missing_col, positive_col, non_zero_col, dtype_dic)\n",
    "\n",
    "# Apply function2 to dataframe, and create new column names Industry\n",
    "\n",
    "df_clean['Industry'] = df['GICS'].apply(industry_classifier)\n",
    "\n",
    "### Apply sample filter industries\n",
    "\n",
    "df_clean = sample_filter(df_clean, industry_col = 'Industry', excluded_industries = excluded_industries)\n",
    "df_clean\n",
    "\n",
    "### Filtering Eurozone countries\n",
    "\n",
    "EU19_data = df_clean[df_clean['Country'].isin(EU19_list)]\n",
    "EU19_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39475ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "EU19_data[non_missing_col].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455cf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "EU19_data[var_list].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "EU19_data = EU19_data.replace(['na', 'nan', 'N/A', 'NA', 'NaN'], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace missing values by Mean or zero (using for variables with small number of missing values compared to total obs)\n",
    "values = {'ROA': EU19_data['ROA'].mean(),\n",
    "         'Number of employees': 0,\n",
    "         'Intangible assets': EU19_data['Intangible assets'].mean()}\n",
    "\n",
    "df_replace_missing = EU19_data.fillna(value = values)\n",
    "EU19_data = df_replace_missing\n",
    "EU19_data[var_list].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4beb7",
   "metadata": {},
   "source": [
    "## 4. Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d9c6",
   "metadata": {},
   "source": [
    "### 1. Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Control variables\n",
    "\n",
    "df = EU19_data\n",
    "\n",
    "df['Net_assets'] = df['Total assets'] - df['Total liabilities']\n",
    "\n",
    "### Firm size\n",
    "df['log_Firm_size'] = np.log(df['Net sales'])\n",
    "\n",
    "### Tangibility\n",
    "df['Tangible_assets'] = df['Total assets'] - df['Intangible assets']\n",
    "df['Tangibility'] = df['Tangible_assets'] / df['Total assets']\n",
    "\n",
    "### Log transformmation of Market capitalization\n",
    "df['log_MarketCap'] = np.log(df['Market Cap.'])\n",
    "\n",
    "### Add constant parameter for regression estimation\n",
    "df['const'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning zero values after calucation\n",
    "\n",
    "df = df.loc[df['Net_assets'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb974da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Leverage calculations\n",
    "\n",
    "### Leverage ratio : calculated by Total liabilities / Total assets\n",
    "\n",
    "df['Total_Leverage'] = df['Total liabilities'] / df['Total assets']\n",
    "\n",
    "### Debt ratio: calculated by Net debt/ Net assets\n",
    "df['Debt_leverage'] = df['Net debt'] / df['Net_assets']\n",
    "\n",
    "Leverage_variables = ['Total_Leverage', 'Debt_leverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5aa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Debt_leverage', 'Net debt', 'Net_assets', 'Tangibility']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460448d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treating outlier by winzorization\n",
    "winzorized_var = ['log_MarketCap', 'ROA', 'log_Firm_size', 'Tangibility', 'Total_Leverage', 'Debt_leverage']\n",
    "df_w = winsorization(df, variables = winzorized_var, by = 'Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d798525b",
   "metadata": {},
   "source": [
    "### 2. Statistic description and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ca762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry = df['Industry'].unique()\n",
    "Industry_data = pd.DataFrame()\n",
    "num_company = []\n",
    "for industry in df_industry:\n",
    "    num = df_w.loc[df['Industry'] == f'{industry}']['Company'].nunique()\n",
    "    num_company.append(num)\n",
    "Industry_data['Industry'] =  df_industry\n",
    "Industry_data['Number of Comapny'] = num_company\n",
    "Industry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Descriptive statistics table:\n",
    "\n",
    "descriptive_table = df_w.groupby('Year').agg({'Total_Leverage_w': ['mean', 'std'], 'Debt_leverage_w': ['mean', 'std'],\n",
    "                                              'log_MarketCap_w': ['mean', 'std'], 'ROA_w': ['mean', 'std'],\n",
    "                                          'log_Firm_size_w': ['mean', 'std'], 'Tangibility_w': ['mean', 'std']})\n",
    "\n",
    "\n",
    "descriptive_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e78413",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = ''\n",
    "OUTPUT_FILE_NAME = 'EU19_Descriptive_Table.xlsx'\n",
    "descriptive_table.to_excel(f'{OUTPUT_DIR}{OUTPUT_FILE_NAME}', sheet_name = 'EU19 Stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57272fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2004, 2013)\n",
    "debt_leverage = pd.Series(index=years)\n",
    "\n",
    "for year in years:\n",
    "    debt_leverage[year] = df_w.loc[df_w['Year'] == year, 'Debt_leverage_w'].median()\n",
    "    \n",
    "    \n",
    "x = years\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, debt_leverage, 'b-', linewidth=2, label = 'Debt Leverage')\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Ratio')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_var = ['log_MarketCap_w', 'ROA_w', 'log_Firm_size_w', 'Tangibility_w']\n",
    "corr_matrix = df_w[['Total_Leverage_w'] + ['Debt_leverage_w']+ control_var].corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = ['Total_Leverage_w','Debt_leverage_w','log_MarketCap_w', 'ROA_w', 'log_Firm_size_w', 'Tangibility_w']\n",
    "df_corr = df_w[corr_list]\n",
    "\n",
    "plt.figure(figsize = (5,4))\n",
    "sns.heatmap(df_corr.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How many companies are left (after cleaning missing values for main variables, and excluding financial industries)\n",
    "\n",
    "unique_com = df_w['Company'].nunique()\n",
    "unique_com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49358b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How many years:\n",
    "unique_yr = df_w['Year'].unique()\n",
    "unique_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### which countries are included:\n",
    "unique_country = sorted(EU19_data['Country'].unique())\n",
    "unique_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### what industries ar included:\n",
    "industries = sorted(EU19_data['Industry'].unique())\n",
    "industries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040db623",
   "metadata": {},
   "source": [
    "### 3. Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe329e5",
   "metadata": {},
   "source": [
    "### 1. OLS with time-fixed effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create time period dummies\n",
    "\n",
    "Pre_crisis_yr = range(2004, 2007)\n",
    "Crisis_yr = range(2007, 2010)\n",
    "Post_crisis_yr = range(2010, 2013)\n",
    "\n",
    "df_w['Pre_crisis_dummy'] = 0\n",
    "df_w['Crisis_dummy'] = 0\n",
    "df_w['Post_crisis_dummy'] = 0\n",
    "\n",
    "for year in year_arr:\n",
    "    if year in Pre_crisis_yr:\n",
    "        df_w.loc[df_w['Year'] == year, 'Pre_crisis_dummy'] = 1\n",
    "    elif year in Crisis_yr:\n",
    "        df_w.loc[df_w['Year'] == year, 'Crisis_dummy'] = 1\n",
    "    elif year in Post_crisis_yr:\n",
    "        df_w.loc[df_w['Year'] == year, 'Post_crisis_dummy'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w[['Year', 'Pre_crisis_dummy', 'Crisis_dummy', 'Post_crisis_dummy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a511ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear regrssion with time period dummies, taking Crisis_dummy as reference time\n",
    "\n",
    "## Case 1: 'Total leverage' as outcome variable\n",
    "\n",
    "X = ['log_MarketCap_w', 'ROA_w', 'log_Firm_size_w', 'Tangibility_w',\n",
    "    'Pre_crisis_dummy', 'Post_crisis_dummy', 'const']\n",
    "\n",
    "Y = 'Total_Leverage_w'\n",
    "\n",
    "\n",
    "reg1 = sm.OLS(endog = df_w[Y],\n",
    "             exog = df_w[X],\n",
    "             missing = 'drop')\n",
    "\n",
    "results1 = reg1.fit().get_robustcov_results(cov_type = 'HC0')\n",
    "\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case 2: 'Debt_leverage' as outcome variable\n",
    "\n",
    "x = ['log_MarketCap_w', 'ROA_w', 'log_Firm_size_w', 'Tangibility_w',\n",
    "    'Pre_crisis_dummy', 'Post_crisis_dummy', 'const']\n",
    "\n",
    "y = 'Debt_leverage_w'\n",
    "\n",
    "\n",
    "\n",
    "reg2 = sm.OLS(endog = df_w[y],\n",
    "             exog = df_w[x],\n",
    "             missing = 'drop')\n",
    "\n",
    "results2 = reg2.fit().get_robustcov_results(cov_type = 'HC0')\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165449db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print linear regression results\n",
    "\n",
    "results_file = summary_col([results1,results2],stars=True)\n",
    "\n",
    "\n",
    "print(results_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e854d",
   "metadata": {},
   "source": [
    "### 2. Panel regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting panel data\n",
    "\n",
    "df_w.set_index(['Company', 'Year'], inplace=True)\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c8e8c",
   "metadata": {},
   "source": [
    "#### Total leverage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45523456",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Panel regression: with time fixed effect - Period dummies\n",
    "\n",
    "x_1 = ['log_MarketCap_w', 'ROA_w', 'log_Firm_size_w', 'Tangibility_w', 'const']\n",
    "\n",
    "y_1 = 'Total_Leverage_w'\n",
    "\n",
    "period_dummies_1 = ['Pre_crisis_dummy', 'Post_crisis_dummy']\n",
    "\n",
    "panel_model_1 = PanelOLS.from_formula(y_1 + ' ~ ' + ' + '.join(x_1) +' + ' + ' + '.join(period_dummies_1), df_w, check_rank=False)\n",
    "\n",
    "results3 = panel_model_1.fit(cov_type = 'robust')\n",
    "\n",
    "print(results3.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Panel regression: with interaction term - Post_crisis * ROA\n",
    "\n",
    "period_dummies_2 = ['Crisis_dummy', 'Post_crisis_dummy']\n",
    "\n",
    "panel_model_2 = PanelOLS.from_formula(y_1 + ' ~ ' + ' + '.join(x_1) +' + ' + ' + '.join(period_dummies_2) + '+ ROA_w * Crisis_dummy' + ' + ROA_w * Post_crisis_dummy', df_w, check_rank=False)\n",
    "\n",
    "results4 = panel_model_2.fit(cov_type = 'robust')\n",
    "\n",
    "print(results4.summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb134af",
   "metadata": {},
   "source": [
    "#### Debt Leverage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2447f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Panel regression: with time fixed effect - Period dummies\n",
    "\n",
    "x_1 = ['log_MarketCap_w', 'ROA_w', 'log_Firm_size_w', 'Tangibility_w', 'const']\n",
    "\n",
    "period_dummies_1 = ['Pre_crisis_dummy', 'Post_crisis_dummy']\n",
    "\n",
    "panel_model_3 = PanelOLS.from_formula(y + ' ~ ' + ' + '.join(x_1) +' + ' + ' + '.join(period_dummies_1), df_w, check_rank=False)\n",
    "\n",
    "results5 = panel_model_3.fit(cov_type = 'robust')\n",
    "\n",
    "print(results5.summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Panel regression: with interaction term - Post_crisis * ROA\n",
    "\n",
    "period_dummies_2 = ['Crisis_dummy', 'Post_crisis_dummy']\n",
    "\n",
    "panel_model_4 = PanelOLS.from_formula(y + ' ~ ' + ' + '.join(x_1) +' + ' + ' + '.join(period_dummies_2) + '+ ROA_w * Crisis_dummy' + ' + ROA_w * Post_crisis_dummy', df_w, check_rank=False)\n",
    "\n",
    "results6 = panel_model_4.fit(cov_type = 'robust')\n",
    "\n",
    "print(results6.summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd126999",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print panel regression results\n",
    "\n",
    "summary_table = compare({'panel_model_1': results3, 'panel_model_2': results4,\n",
    "                         'panel_model_3': results5, 'panel_model_4': results6},stars=True)\n",
    "print(summary_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
